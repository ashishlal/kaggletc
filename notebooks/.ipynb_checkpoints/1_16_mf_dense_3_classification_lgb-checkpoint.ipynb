{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse as ssp\n",
    "from sklearn.model_selection import KFold,train_test_split,StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import xgboost as xgb\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "# from generate_selftrained_w2v import gen_w2v\n",
    "# from config import path\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import log_loss,roc_auc_score\n",
    "import lightgbm as lgbm\n",
    "\n",
    "path = '../cache/'\n",
    "seed = 1024\n",
    "np.random.seed(seed)\n",
    "# path = '../input/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('../cache/X.npy')\n",
    "X_t = np.load('../cache/X_t.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.load('../cache/y1.npy')\n",
    "y2 = np.load('../cache/y2.npy')\n",
    "y3 = np.load('../cache/y3.npy')\n",
    "y4 = np.load('../cache/y4.npy')\n",
    "y5 = np.load('../cache/y5.npy')\n",
    "y6 = np.load('../cache/y6.npy')\n",
    "y7 = np.load('../cache/y7.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import make_mf_classification\n",
    "\n",
    "X = pd.DataFrame(X).replace(np.nan,0).values\n",
    "X_t = pd.DataFrame(X_t).replace(np.nan,0).values\n",
    "X = pd.DataFrame(X).replace(np.inf,0).values\n",
    "X_t = pd.DataFrame(X_t).replace(np.inf,0).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 83)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 83)\n"
     ]
    }
   ],
   "source": [
    "print(X_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y7[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "Y = []\n",
    "for i in range(len(list(y7))):\n",
    "      Y.append(y7[i][5] + 2* y7[i][4] + 4* y7[i][3] + 8* y7[i][3] + 16* y7[i][1] + 32* y7[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# clf = lgb.LGBMClassifier(\n",
    "#                         num_leaves=31,\n",
    "#                         learning_rate= 0.008,\n",
    "#                         n_estimators=8192,\n",
    "#                         subsample = 0.75,\n",
    "#                         colsample_bytree = 0.54,\n",
    "#                         min_child_weight=13,\n",
    "#                         min_split_gain=0.3,\n",
    "#                         )\n",
    "\n",
    "# make_mf_classification(X ,y1, clf, X_t, n_folds=5,seed=seed,nb_epoch=1,max_features=1.0,name='lgb_3',path=path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../submissions/submission_0.986.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_prime = df['toxic'].values\n",
    "y2_prime = df['severe_toxic'].values\n",
    "y3_prime = df['obscene'].values\n",
    "y4_prime = df['threat'].values\n",
    "y5_prime = df['insult'].values\n",
    "y6_prime = df['identity_hate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prime = np.vstack([X,X_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_prime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153164"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(y1_prime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = list(y1_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153164"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9712006150071396,\n",
       " 0.024166994145549615,\n",
       " 0.028506825621810027,\n",
       " 0.022757149260101275,\n",
       " 0.02991696385932168,\n",
       " 0.024202996804080324,\n",
       " 0.025997587335918584,\n",
       " 0.5015530023934763,\n",
       " 0.10345659679592364,\n",
       " 0.022704060821645226,\n",
       " 0.4692673022688327,\n",
       " 0.2203601356377492,\n",
       " 0.026544477747138282,\n",
       " 0.0238192921183635,\n",
       " 0.022933715412303383,\n",
       " 0.026530359231891124,\n",
       " 0.03285724984888777,\n",
       " 0.03076132899642822,\n",
       " 0.02182102366179385,\n",
       " 0.029451714906829667,\n",
       " 0.029239252535024823,\n",
       " 0.6290787361998013,\n",
       " 0.2053396223259983,\n",
       " 0.023879429462453226,\n",
       " 0.13571667869233736,\n",
       " 0.028249619316346144,\n",
       " 0.025579346389975804,\n",
       " 0.058601079944405075,\n",
       " 0.16951240972277085,\n",
       " 0.026927038488017526,\n",
       " 0.024411191731595144,\n",
       " 0.03439732244541524,\n",
       " 0.02347287979094884,\n",
       " 0.023041691216763974,\n",
       " 0.10283338030327928,\n",
       " 0.02981889929027771,\n",
       " 0.022861956868139497,\n",
       " 0.04565304489915832,\n",
       " 0.3497371398777766,\n",
       " 0.02859398031032741,\n",
       " 0.02611878305137702,\n",
       " 0.04568430849352708,\n",
       " 0.0262801645076842,\n",
       " 0.024047387621675458,\n",
       " 0.03908457650051955,\n",
       " 0.024442055956710968,\n",
       " 0.040612448687641266,\n",
       " 0.02161497456285777,\n",
       " 0.982703254775038,\n",
       " 0.029213055211285782,\n",
       " 0.6912804669665633,\n",
       " 0.023882949826455408,\n",
       " 0.027053454619852826,\n",
       " 0.025867314424249686,\n",
       " 0.02456910547802868,\n",
       " 0.02382812130288408,\n",
       " 0.8651474886488273,\n",
       " 0.032384625809685964,\n",
       " 0.0304406522125324,\n",
       " 0.9821724451922148,\n",
       " 0.09401009911198853,\n",
       " 0.031097006904438937,\n",
       " 0.030108995043904106,\n",
       " 0.6709514108857006,\n",
       " 0.036321018679151176,\n",
       " 0.14733468756877635,\n",
       " 0.05222490900383649,\n",
       " 0.050899680981724364,\n",
       " 0.033117583753176534,\n",
       " 0.02723387604389984,\n",
       " 0.984777679359885,\n",
       " 0.2661211208650996,\n",
       " 0.024955802696639526,\n",
       " 0.025495014801210643,\n",
       " 0.7036585450743846,\n",
       " 0.06658330955606995,\n",
       " 0.2671820516396003,\n",
       " 0.033925758452486715,\n",
       " 0.8517191200653249,\n",
       " 0.10243971822081273,\n",
       " 0.021931182141370832,\n",
       " 0.954793267052865,\n",
       " 0.025334956501933282,\n",
       " 0.023697661219455598,\n",
       " 0.027840175031184126,\n",
       " 0.021859113914699496,\n",
       " 0.02374528909138624,\n",
       " 0.023044754965191733,\n",
       " 0.023584977334578924,\n",
       " 0.024471140016443668,\n",
       " 0.02772996286722886,\n",
       " 0.02509181294940526,\n",
       " 0.9724279726253341,\n",
       " 0.022151630138977876,\n",
       " 0.024376477490924187,\n",
       " 0.028737706727386538,\n",
       " 0.04824650400839405,\n",
       " 0.026893257343951867,\n",
       " 0.023009700404729508,\n",
       " 0.9712115347603244,\n",
       " 0.02633510310554801,\n",
       " 0.025435279154424083,\n",
       " 0.0310565143857302,\n",
       " 0.09605486878398274,\n",
       " 0.023742081090925925,\n",
       " 0.024418502838743132,\n",
       " 0.15998953510234382,\n",
       " 0.029265778680763167,\n",
       " 0.02497461446978186,\n",
       " 0.9456542211013792,\n",
       " 0.02253624687961584,\n",
       " 0.3635880428137942,\n",
       " 0.023247665711441885,\n",
       " 0.025219301432005854,\n",
       " 0.10948995885392013,\n",
       " 0.021478641826498918,\n",
       " 0.02719149991855761,\n",
       " 0.024111423891702843,\n",
       " 0.6534380030604144,\n",
       " 0.10524888963938722,\n",
       " 0.04127356502681371,\n",
       " 0.1724501944418908,\n",
       " 0.0218206609134956,\n",
       " 0.02461335557311833,\n",
       " 0.028167117779218112,\n",
       " 0.022323707192637064,\n",
       " 0.9778094354833212,\n",
       " 0.028876935398607,\n",
       " 0.1540047726911146,\n",
       " 0.9733500610474279,\n",
       " 0.02280669497986292,\n",
       " 0.15671705422411136,\n",
       " 0.8865015611929591,\n",
       " 0.08890783095049637,\n",
       " 0.034846373546912605,\n",
       " 0.039371977542000426,\n",
       " 0.9831037742395046,\n",
       " 0.03833241202246754,\n",
       " 0.02285443436864596,\n",
       " 0.05477279720165154,\n",
       " 0.02457761681562903,\n",
       " 0.02715785145607836,\n",
       " 0.022441552237649903,\n",
       " 0.08770640623804472,\n",
       " 0.20159887354096845,\n",
       " 0.028165439229523782,\n",
       " 0.030110057879303542,\n",
       " 0.02707040874089656,\n",
       " 0.022731199706555426,\n",
       " 0.05168972950080445,\n",
       " 0.02871772081623347,\n",
       " 0.023520934788742072,\n",
       " 0.2779665773916286,\n",
       " 0.05907086364834295,\n",
       " 0.09898006933266276,\n",
       " 0.1353448263923868,\n",
       " 0.8667025515118408,\n",
       " 0.0333500532720769,\n",
       " 0.023688972238379933,\n",
       " 0.025475413623634903,\n",
       " 0.02418837341702711,\n",
       " 0.024485463362499637,\n",
       " 0.5488874719393159,\n",
       " 0.023113666286759232,\n",
       " 0.023894196202769585,\n",
       " 0.08230085492913303,\n",
       " 0.04057553920874221,\n",
       " 0.029374120512085038,\n",
       " 0.4178088204854683,\n",
       " 0.03126108200946442,\n",
       " 0.9121486925585096,\n",
       " 0.028988235410475505,\n",
       " 0.059877935425391986,\n",
       " 0.023401005450017883,\n",
       " 0.9428932918678704,\n",
       " 0.9650809706024188,\n",
       " 0.029023731925950595,\n",
       " 0.02939681683994645,\n",
       " 0.8937594223640655,\n",
       " 0.6670607215436353,\n",
       " 0.02326746751255577,\n",
       " 0.02856575226322965,\n",
       " 0.02354697287944769,\n",
       " 0.20826967512019712,\n",
       " 0.16155688377575586,\n",
       " 0.030427803809325676,\n",
       " 0.2964650217312571,\n",
       " 0.03995184848398891,\n",
       " 0.7432581857948015,\n",
       " 0.9709265660376,\n",
       " 0.029623033334609014,\n",
       " 0.02854030472563672,\n",
       " 0.7886656576919923,\n",
       " 0.9854533055580584,\n",
       " 0.7830673029794667,\n",
       " 0.02376754539532971,\n",
       " 0.061892567816044734,\n",
       " 0.6390566880854056,\n",
       " 0.2063952174557829,\n",
       " 0.025672840795037243,\n",
       " 0.025197368818314997,\n",
       " 0.7868166272799991,\n",
       " 0.024663933048720013,\n",
       " 0.05112486420413015,\n",
       " 0.03431787466151317,\n",
       " 0.02237931922455402,\n",
       " 0.06095208450236025,\n",
       " 0.22717181820838075,\n",
       " 0.3358187785451775,\n",
       " 0.026452160223014918,\n",
       " 0.02565725036176135,\n",
       " 0.9868518085505741,\n",
       " 0.0390419594623654,\n",
       " 0.02585517658063091,\n",
       " 0.08140211224891576,\n",
       " 0.9446959874370152,\n",
       " 0.2062806343644386,\n",
       " 0.021909501787565844,\n",
       " 0.6664433004720096,\n",
       " 0.5399778252723335,\n",
       " 0.022322016637746238,\n",
       " 0.02442854143560328,\n",
       " 0.024229504357601083,\n",
       " 0.02418628033859784,\n",
       " 0.03351920823946506,\n",
       " 0.02199714676593494,\n",
       " 0.022846082045531364,\n",
       " 0.06415030468710194,\n",
       " 0.03087167421462178,\n",
       " 0.02863298685409825,\n",
       " 0.024279324741059642,\n",
       " 0.03240368548043753,\n",
       " 0.0680439782578442,\n",
       " 0.02336013642319574,\n",
       " 0.02206467693814511,\n",
       " 0.7946672675903964,\n",
       " 0.8141614659103967,\n",
       " 0.030637161994116688,\n",
       " 0.02300904584470313,\n",
       " 0.023664346698182633,\n",
       " 0.024135571757183682,\n",
       " 0.02361941548845226,\n",
       " 0.023264785272423073,\n",
       " 0.025303914704806484,\n",
       " 0.04525348077575424,\n",
       " 0.027616517957284138,\n",
       " 0.5836408090065788,\n",
       " 0.09399565655392177,\n",
       " 0.04823238238394911,\n",
       " 0.02695862781557549,\n",
       " 0.03144850503642785,\n",
       " 0.14279673517632893,\n",
       " 0.8016574726313238,\n",
       " 0.025520121645005427,\n",
       " 0.031319894879193615,\n",
       " 0.5345481302102397,\n",
       " 0.9833479344527036,\n",
       " 0.021524667092971232,\n",
       " 0.5988251989175896,\n",
       " 0.8487030538855002,\n",
       " 0.4108924428885764,\n",
       " 0.04314491690678728,\n",
       " 0.03841491921652347,\n",
       " 0.4767601155140778,\n",
       " 0.024024138341985062,\n",
       " 0.6210654995268658,\n",
       " 0.031308226099176564,\n",
       " 0.03939847755218327,\n",
       " 0.026666322757849862,\n",
       " 0.022946816380272538,\n",
       " 0.12304398212334072,\n",
       " 0.022003461155311845,\n",
       " 0.02635602555598029,\n",
       " 0.02242264189514928,\n",
       " 0.08886676230179033,\n",
       " 0.023861777091192183,\n",
       " 0.025945392063685263,\n",
       " 0.978683939651164,\n",
       " 0.03846637191366457,\n",
       " 0.9056848556955992,\n",
       " 0.029841912907627163,\n",
       " 0.02344738148133669,\n",
       " 0.06305294621621503,\n",
       " 0.030106392698917607,\n",
       " 0.20447585469404675,\n",
       " 0.022476315126640483,\n",
       " 0.05207296081337305,\n",
       " 0.02479347653243108,\n",
       " 0.032260386614531435,\n",
       " 0.3227190625466197,\n",
       " 0.02219288712281658,\n",
       " 0.033927308955536965,\n",
       " 0.1125629439951228,\n",
       " 0.6671092562217839,\n",
       " 0.05968573530732571,\n",
       " 0.02846399147328138,\n",
       " 0.02940711051605377,\n",
       " 0.025064874299224032,\n",
       " 0.9782065466469648,\n",
       " 0.18047899311949697,\n",
       " 0.025273571792815662,\n",
       " 0.9321405168438576,\n",
       " 0.9094663645154192,\n",
       " 0.2530852275940422,\n",
       " 0.024270950615226446,\n",
       " 0.9736202374750468,\n",
       " 0.024678052731049564,\n",
       " 0.022218672180170332,\n",
       " 0.034919453604364895,\n",
       " 0.9688153788837208,\n",
       " 0.12561597538106753,\n",
       " 0.0239447849818641,\n",
       " 0.7261274891358889,\n",
       " 0.21710911472259856,\n",
       " 0.4922422855041361,\n",
       " 0.02400557128008997,\n",
       " 0.02819889423901724,\n",
       " 0.02511791606233013,\n",
       " 0.5878392870512459,\n",
       " 0.9679268190211396,\n",
       " 0.5646115933903411,\n",
       " 0.048955081959323375,\n",
       " 0.026661219452501814,\n",
       " 0.027978595640640272,\n",
       " 0.02288092419961588,\n",
       " 0.027115308726064786,\n",
       " 0.04963205668537099,\n",
       " 0.026085376842956958,\n",
       " 0.03664515366122119,\n",
       " 0.7563570711611208,\n",
       " 0.8854107454835765,\n",
       " 0.3756650879836587,\n",
       " 0.9819126492639824,\n",
       " 0.4771684617508019,\n",
       " 0.02207050580790603,\n",
       " 0.02499683628096046,\n",
       " 0.9864618142340208,\n",
       " 0.2404259543840643,\n",
       " 0.07927956458060299,\n",
       " 0.809897591591546,\n",
       " 0.02967539780191509,\n",
       " 0.02237980620186769,\n",
       " 0.048293481308154924,\n",
       " 0.028908527959191806,\n",
       " 0.03781948804661295,\n",
       " 0.02721022875463201,\n",
       " 0.02692169139941744,\n",
       " 0.9086950853527364,\n",
       " 0.02531009286559491,\n",
       " 0.9852308092487764,\n",
       " 0.02729344369863949,\n",
       " 0.024132219882981504,\n",
       " 0.025069230441715,\n",
       " 0.035981027431197105,\n",
       " 0.02507381678516277,\n",
       " 0.9672377230220932,\n",
       " 0.024151730646546733,\n",
       " 0.09942494036573467,\n",
       " 0.02417609011961052,\n",
       " 0.028933195252118377,\n",
       " 0.9824531692831364,\n",
       " 0.9535906613291596,\n",
       " 0.04988313163794969,\n",
       " 0.053675625696898106,\n",
       " 0.9241754085322259,\n",
       " 0.03573765626411149,\n",
       " 0.033306100036366235,\n",
       " 0.029040937652411232,\n",
       " 0.96162891869695,\n",
       " 0.23620471479990784,\n",
       " 0.669160931938256,\n",
       " 0.021620119269385254,\n",
       " 0.6629663125907208,\n",
       " 0.02747291364508256,\n",
       " 0.0248412373235803,\n",
       " 0.022616447400276025,\n",
       " 0.5848195486926484,\n",
       " 0.03971805979742464,\n",
       " 0.02315427578258344,\n",
       " 0.032364392539767944,\n",
       " 0.9234675942704492,\n",
       " 0.022823808059556274,\n",
       " 0.02510451811169832,\n",
       " 0.08116534653550105,\n",
       " 0.02521880317761953,\n",
       " 0.02396891509929537,\n",
       " 0.029883918729790807,\n",
       " 0.05293056731471372,\n",
       " 0.026496145461639,\n",
       " 0.03201171366212022,\n",
       " 0.031657083161523845,\n",
       " 0.9765735576726448,\n",
       " 0.025119882329697717,\n",
       " 0.03006360047472931,\n",
       " 0.026508357894277516,\n",
       " 0.964278861467788,\n",
       " 0.025771543896638157,\n",
       " 0.8821315637739808,\n",
       " 0.059206266111484024,\n",
       " 0.7989806153780411,\n",
       " 0.02302760168296395,\n",
       " 0.027379033547076933,\n",
       " 0.08473680901710356,\n",
       " 0.0278750426410494,\n",
       " 0.035416793409358896,\n",
       " 0.023596805988718585,\n",
       " 0.02393201523767401,\n",
       " 0.10276964409440374,\n",
       " 0.02778901925705477,\n",
       " 0.021982292849474814,\n",
       " 0.024311809362039503,\n",
       " 0.036640198106131096,\n",
       " 0.02402194931157138,\n",
       " 0.12443134833544207,\n",
       " 0.028068968930156958,\n",
       " 0.0224644684878735,\n",
       " 0.8584989542370618,\n",
       " 0.027439207966038225,\n",
       " 0.02424272471621013,\n",
       " 0.12296629812995842,\n",
       " 0.07041309231536602,\n",
       " 0.029137947198632694,\n",
       " 0.024710144318662215,\n",
       " 0.024866984192276127,\n",
       " 0.0223425800812515,\n",
       " 0.9300044104696884,\n",
       " 0.8374641431046201,\n",
       " 0.6258096679083986,\n",
       " 0.027328150825511648,\n",
       " 0.025551400016319538,\n",
       " 0.025596552559108983,\n",
       " 0.0254068137073432,\n",
       " 0.025673500906441854,\n",
       " 0.023581390082404424,\n",
       " 0.02524052701925801,\n",
       " 0.0255428445483904,\n",
       " 0.20277044130291352,\n",
       " 0.6536529430363374,\n",
       " 0.27147250650147364,\n",
       " 0.8820334821401171,\n",
       " 0.035772789113867214,\n",
       " 0.06282578816742966,\n",
       " 0.02344041315615003,\n",
       " 0.043776896111537934,\n",
       " 0.23286312570504997,\n",
       " 0.8365943075561946,\n",
       " 0.04114390145050941,\n",
       " 0.023518982790952228,\n",
       " 0.8588335368012412,\n",
       " 0.024493285572569343,\n",
       " 0.0222223214738117,\n",
       " 0.04961893559660021,\n",
       " 0.05471636755749122,\n",
       " 0.023912921969126408,\n",
       " 0.5335867991975306,\n",
       " 0.19885563412693744,\n",
       " 0.028046350215343338,\n",
       " 0.02609415720818457,\n",
       " 0.02134636664498752,\n",
       " 0.02456261699631354,\n",
       " 0.026360288496015082,\n",
       " 0.6767234577013574,\n",
       " 0.03453901380992325,\n",
       " 0.5927673890883715,\n",
       " 0.026974462884284747,\n",
       " 0.02368727559120097,\n",
       " 0.025800336080763167,\n",
       " 0.3496287338104516,\n",
       " 0.18524190280930874,\n",
       " 0.3422883087259546,\n",
       " 0.038035232589778735,\n",
       " 0.022789495668981728,\n",
       " 0.024944473507016264,\n",
       " 0.9582936488173444,\n",
       " 0.9739779083755058,\n",
       " 0.95579173298195,\n",
       " 0.06010928034606791,\n",
       " 0.111356887859327,\n",
       " 0.028643344545007225,\n",
       " 0.05575113451118952,\n",
       " 0.023461245810695083,\n",
       " 0.98984642795434,\n",
       " 0.9818094232609169,\n",
       " 0.022499922346690442,\n",
       " 0.229793712268648,\n",
       " 0.10663858615169183,\n",
       " 0.02288012932504806,\n",
       " 0.02765191613950101,\n",
       " 0.022324268878347445,\n",
       " 0.0231011824356514,\n",
       " 0.34780952109336544,\n",
       " 0.9789750826056351,\n",
       " 0.8590063386887166,\n",
       " 0.11061518033980576,\n",
       " 0.9246523956467254,\n",
       " 0.2590835966414868,\n",
       " 0.24683049304846202,\n",
       " 0.02803170744321009,\n",
       " 0.028643135554031307,\n",
       " 0.9781514684544486,\n",
       " 0.024382883648848108,\n",
       " 0.02665771882177662,\n",
       " 0.026479499417901016,\n",
       " 0.02628328270289689,\n",
       " 0.966963375917202,\n",
       " 0.02217076600764974,\n",
       " 0.14790796717453766,\n",
       " 0.0366026298612936,\n",
       " 0.7969363341434759,\n",
       " 0.025683895378943628,\n",
       " 0.8211771852684813,\n",
       " 0.024568932334374197,\n",
       " 0.032680434015498964,\n",
       " 0.0375962658246338,\n",
       " 0.7177762940606638,\n",
       " 0.20469863056479853,\n",
       " 0.02528278188335304,\n",
       " 0.21577059778013294,\n",
       " 0.022711937158771726,\n",
       " 0.9224216016389768,\n",
       " 0.05000993499675666,\n",
       " 0.035667711615650494,\n",
       " 0.08679393943960269,\n",
       " 0.3729831988308467,\n",
       " 0.0810600334822301,\n",
       " 0.02437974251792221,\n",
       " 0.05243176787314365,\n",
       " 0.02978870066119925,\n",
       " 0.2160798724118592,\n",
       " 0.024048854189772696,\n",
       " 0.028582794485050605,\n",
       " 0.02174679076389015,\n",
       " 0.028942345475697205,\n",
       " 0.930189120990216,\n",
       " 0.7019323279823912,\n",
       " 0.03518012550961763,\n",
       " 0.9108870142713354,\n",
       " 0.026467131198930037,\n",
       " 0.2796368717488422,\n",
       " 0.023079120075506627,\n",
       " 0.9742776438855518,\n",
       " 0.027882961071177145,\n",
       " 0.04288299790745875,\n",
       " 0.5447844713961395,\n",
       " 0.6657359229726991,\n",
       " 0.024086021573120963,\n",
       " 0.021778609330806054,\n",
       " 0.19751914727049524,\n",
       " 0.03920275327765685,\n",
       " 0.023018219838212884,\n",
       " 0.02595427508385807,\n",
       " 0.4534034901271159,\n",
       " 0.03149501826960052,\n",
       " 0.023031503243853828,\n",
       " 0.03287945659794867,\n",
       " 0.15196224023869995,\n",
       " 0.02323985486807366,\n",
       " 0.7678606497035404,\n",
       " 0.026756584991609062,\n",
       " 0.7700620966140118,\n",
       " 0.046869635231739454,\n",
       " 0.029278928063481414,\n",
       " 0.05495565961629683,\n",
       " 0.7618241992652961,\n",
       " 0.02252818382471866,\n",
       " 0.02307449287738266,\n",
       " 0.028462552306578418,\n",
       " 0.025447633816607414,\n",
       " 0.13716241826563935,\n",
       " 0.5013968041774585,\n",
       " 0.4841058542509737,\n",
       " 0.6754997374084838,\n",
       " 0.08475499460883988,\n",
       " 0.9721907485090456,\n",
       " 0.8830652480561108,\n",
       " 0.28880467419507405,\n",
       " 0.023040706671418443,\n",
       " 0.03991958905336143,\n",
       " 0.09989520590890004,\n",
       " 0.02669512604574491,\n",
       " 0.022871868655751082,\n",
       " 0.13500534879984505,\n",
       " 0.11453843161179915,\n",
       " 0.02892520546290405,\n",
       " 0.03829729321296919,\n",
       " 0.06814402584964302,\n",
       " 0.034942410933443524,\n",
       " 0.02432955460434656,\n",
       " 0.961312439946344,\n",
       " 0.02613337648283039,\n",
       " 0.6047876496994913,\n",
       " 0.023073508373694783,\n",
       " 0.4711780213167547,\n",
       " 0.023977172741069645,\n",
       " 0.6428270154002633,\n",
       " 0.10892094935145563,\n",
       " 0.024506571020542843,\n",
       " 0.0331064708354672,\n",
       " 0.025871363832485863,\n",
       " 0.6001280482315748,\n",
       " 0.1094403333470183,\n",
       " 0.025896779630645128,\n",
       " 0.19912559162602897,\n",
       " 0.026013362107985296,\n",
       " 0.028662846497794364,\n",
       " 0.08957158860418207,\n",
       " 0.02592955299375404,\n",
       " 0.024613021021910642,\n",
       " 0.037776421282915744,\n",
       " 0.0248982785119326,\n",
       " 0.03222652411000697,\n",
       " 0.024937338339846404,\n",
       " 0.03201082204667089,\n",
       " 0.029868764127984383,\n",
       " 0.0266526718964233,\n",
       " 0.03905068995598629,\n",
       " 0.4461263117845629,\n",
       " 0.30244479254533024,\n",
       " 0.4340061754970415,\n",
       " 0.025005907608717674,\n",
       " 0.053300110353209335,\n",
       " 0.9493700124895964,\n",
       " 0.02717876505375341,\n",
       " 0.8196148732023923,\n",
       " 0.964669779447838,\n",
       " 0.02332587668885382,\n",
       " 0.9000193428978679,\n",
       " 0.8891794359472072,\n",
       " 0.521214958145021,\n",
       " 0.025550414072406127,\n",
       " 0.9653717131880734,\n",
       " 0.048393839708334815,\n",
       " 0.2234553066791591,\n",
       " 0.023832496181918492,\n",
       " 0.024985139192653827,\n",
       " 0.1000007719126964,\n",
       " 0.023508058246026118,\n",
       " 0.1837027058382016,\n",
       " 0.6861975593298302,\n",
       " 0.6487347652178607,\n",
       " 0.30530263949801745,\n",
       " 0.08909565674661203,\n",
       " 0.055239924500925006,\n",
       " 0.023857405794063074,\n",
       " 0.5923127029183289,\n",
       " 0.023513401208054015,\n",
       " 0.024346484891372817,\n",
       " 0.4623844581393226,\n",
       " 0.980440109599134,\n",
       " 0.4706632478578962,\n",
       " 0.02385806471363684,\n",
       " 0.02418995562749074,\n",
       " 0.09552024423327317,\n",
       " 0.9121506065688992,\n",
       " 0.022304862520471563,\n",
       " 0.025907392381497172,\n",
       " 0.04635539155151922,\n",
       " 0.024485780337395336,\n",
       " 0.9341237438556302,\n",
       " 0.02419773376326709,\n",
       " 0.02648370282461424,\n",
       " 0.02719678953735959,\n",
       " 0.08519339322638886,\n",
       " 0.023706055411464283,\n",
       " 0.6029513760098031,\n",
       " 0.03102479827821845,\n",
       " 0.4423021338762405,\n",
       " 0.024553091060835145,\n",
       " 0.02442561799115064,\n",
       " 0.025167534870581827,\n",
       " 0.03515448021231081,\n",
       " 0.36741622453200223,\n",
       " 0.023154405272602298,\n",
       " 0.04622297333601032,\n",
       " 0.1030518545243651,\n",
       " 0.6383937946588026,\n",
       " 0.03271265322055966,\n",
       " 0.02364007862357787,\n",
       " 0.7904990825440713,\n",
       " 0.4802303849641488,\n",
       " 0.025962353607775462,\n",
       " 0.022493841975985033,\n",
       " 0.031173138078538918,\n",
       " 0.02392768413630196,\n",
       " 0.028609344274351307,\n",
       " 0.026271521093590308,\n",
       " 0.9655740929838226,\n",
       " 0.02234411614604848,\n",
       " 0.07854138316909444,\n",
       " 0.9089496757402568,\n",
       " 0.12301884962064408,\n",
       " 0.05375582700758397,\n",
       " 0.02158872656513474,\n",
       " 0.022000428089693363,\n",
       " 0.41241971600766303,\n",
       " 0.039724055624898384,\n",
       " 0.025733489160929456,\n",
       " 0.02229960650705921,\n",
       " 0.8640424522879149,\n",
       " 0.03657925979348912,\n",
       " 0.028132803772628997,\n",
       " 0.44136523404300987,\n",
       " 0.3548727649130343,\n",
       " 0.5490305957199697,\n",
       " 0.08620832627469796,\n",
       " 0.10919584953244364,\n",
       " 0.025918084782681924,\n",
       " 0.02220642874570216,\n",
       " 0.02689354856631301,\n",
       " 0.02559063962918931,\n",
       " 0.023187735622199585,\n",
       " 0.023603546038108568,\n",
       " 0.8167163149822074,\n",
       " 0.7847240404869844,\n",
       " 0.4836735775873711,\n",
       " 0.0261465354348312,\n",
       " 0.02374556208255615,\n",
       " 0.03008405155234092,\n",
       " 0.5995662431378228,\n",
       " 0.024197052618968755,\n",
       " 0.025156724351402232,\n",
       " 0.05268102849457869,\n",
       " 0.02662094907633609,\n",
       " 0.023917657944545628,\n",
       " 0.023674390322016608,\n",
       " 0.027704714313227886,\n",
       " 0.035616110230678774,\n",
       " 0.042831732724572684,\n",
       " 0.10116009206687264,\n",
       " 0.1977975432367892,\n",
       " 0.023676939482170745,\n",
       " 0.02402781106356857,\n",
       " 0.6148601280066737,\n",
       " 0.034299530494011334,\n",
       " 0.02637915435663543,\n",
       " 0.025138089376461902,\n",
       " 0.3425277524995448,\n",
       " 0.6341168280086447,\n",
       " 0.022853341036446092,\n",
       " 0.057572636247559865,\n",
       " 0.043876877648346885,\n",
       " 0.056971045778413935,\n",
       " 0.12172595282910975,\n",
       " 0.9136333318711741,\n",
       " 0.0244109113720245,\n",
       " 0.4933238966434053,\n",
       " 0.025743024807970732,\n",
       " 0.02459563176729478,\n",
       " 0.023901821840197048,\n",
       " 0.022920379941854262,\n",
       " 0.024188849630362826,\n",
       " 0.9714089877083212,\n",
       " 0.04578140808883098,\n",
       " 0.028991169429704658,\n",
       " 0.022178928291443457,\n",
       " 0.022599368309085616,\n",
       " 0.0224653702138636,\n",
       " 0.3226627713904566,\n",
       " 0.024583543499631724,\n",
       " 0.02244509766512173,\n",
       " 0.05055165846027765,\n",
       " 0.02672718761810458,\n",
       " 0.8705426852152683,\n",
       " 0.885194611964879,\n",
       " 0.029791017678277864,\n",
       " 0.5707731513722529,\n",
       " 0.16871832937390666,\n",
       " 0.02297516907159885,\n",
       " 0.026259180737931945,\n",
       " 0.948553306979222,\n",
       " 0.2564803911748597,\n",
       " 0.023365584659202437,\n",
       " 0.022825168946826523,\n",
       " 0.024920974221420464,\n",
       " 0.5347875266686335,\n",
       " 0.02427139995649472,\n",
       " 0.1421887794508089,\n",
       " 0.07064889637059475,\n",
       " 0.4473178552128877,\n",
       " 0.4875618114661189,\n",
       " 0.02469990068664237,\n",
       " 0.023682500896964068,\n",
       " 0.8648128885311268,\n",
       " 0.03630885896977952,\n",
       " 0.023708736506207768,\n",
       " 0.07450701377023741,\n",
       " 0.9521814995932496,\n",
       " 0.02545872462320629,\n",
       " 0.026530274391416524,\n",
       " 0.0230076268887866,\n",
       " 0.02262773927387314,\n",
       " 0.717852093238858,\n",
       " 0.02225589548224476,\n",
       " 0.14436256896065866,\n",
       " 0.12831291763276148,\n",
       " 0.1108692916713254,\n",
       " 0.025318734343222276,\n",
       " 0.02436496075259486,\n",
       " 0.7288288052814778,\n",
       " 0.03322708592289991,\n",
       " 0.9842982781679817,\n",
       " 0.02521806397819164,\n",
       " 0.022403185259304133,\n",
       " 0.9692215441278726,\n",
       " 0.024386445110836,\n",
       " 0.6388023365032784,\n",
       " 0.02296228154686671,\n",
       " 0.18838871556116984,\n",
       " 0.07270245677133681,\n",
       " 0.18424260007990406,\n",
       " 0.023985417676555668,\n",
       " 0.08735923334953319,\n",
       " 0.9772710788749218,\n",
       " 0.9422182942986352,\n",
       " 0.021789999813268682,\n",
       " 0.02471909414739822,\n",
       " 0.171863435527231,\n",
       " 0.9427128882278908,\n",
       " 0.022801803392972244,\n",
       " 0.0955710018315392,\n",
       " 0.055353946036496994,\n",
       " 0.02310751969835564,\n",
       " 0.022482416035989158,\n",
       " 0.022802118765741248,\n",
       " 0.25055374881941284,\n",
       " 0.02171735982622396,\n",
       " 0.023838237527038463,\n",
       " 0.3367676986418254,\n",
       " 0.6580488772768814,\n",
       " 0.02223307372688805,\n",
       " 0.7300867689428979,\n",
       " 0.0238954498527312,\n",
       " 0.02189002271406209,\n",
       " 0.03530086009533258,\n",
       " 0.9022804873203599,\n",
       " 0.0849081391845613,\n",
       " 0.032666203446056474,\n",
       " 0.9441975924856488,\n",
       " 0.03294127107989561,\n",
       " 0.17665898604097444,\n",
       " 0.02254195663487864,\n",
       " 0.02194848538625559,\n",
       " 0.024993846264500158,\n",
       " 0.022087870762847992,\n",
       " 0.9270463562189404,\n",
       " 0.05332603305814937,\n",
       " 0.5028557488320661,\n",
       " 0.03962729189701536,\n",
       " 0.9119818040138272,\n",
       " 0.9254103583065856,\n",
       " 0.027890503842181474,\n",
       " 0.5832687643116617,\n",
       " 0.024393901349125374,\n",
       " 0.062123732213669826,\n",
       " 0.04055159585283297,\n",
       " 0.9758769033875112,\n",
       " 0.04548977677606905,\n",
       " 0.14120353605846575,\n",
       " 0.08335318012920068,\n",
       " 0.9807639990077556,\n",
       " 0.1593544178282896,\n",
       " 0.024166082914891498,\n",
       " 0.0247104133050032,\n",
       " 0.0283129458314744,\n",
       " 0.02356496461257258,\n",
       " 0.911888416041034,\n",
       " 0.0256026351536567,\n",
       " 0.0287140180578609,\n",
       " 0.02818427181381455,\n",
       " 0.02206071417839125,\n",
       " 0.8152201814731435,\n",
       " 0.023213258104922228,\n",
       " 0.908721758848196,\n",
       " 0.9101272513034592,\n",
       " 0.026026697662821688,\n",
       " 0.02185588215986456,\n",
       " 0.3201946317196705,\n",
       " 0.903460893796732,\n",
       " 0.04747915339376477,\n",
       " 0.8394232308189736,\n",
       " 0.6653442114462323,\n",
       " 0.949588921565148,\n",
       " 0.023371703743170054,\n",
       " 0.9129398271830821,\n",
       " 0.1488192125887189,\n",
       " 0.02268660384033758,\n",
       " 0.02358691371461973,\n",
       " 0.98160585783373,\n",
       " 0.03429075919120424,\n",
       " 0.028612476049385206,\n",
       " 0.6634333506818967,\n",
       " 0.024292559491727917,\n",
       " 0.02277453003145779,\n",
       " 0.023535735574726636,\n",
       " 0.031088698569528606,\n",
       " 0.024194561853375623,\n",
       " 0.022459858929930614,\n",
       " 0.04241466755621267,\n",
       " 0.1082270931483417,\n",
       " 0.025748677068320253,\n",
       " 0.02690779434740808,\n",
       " 0.09339744751596303,\n",
       " 0.03861000002451689,\n",
       " 0.36765258723950056,\n",
       " 0.03665547919617052,\n",
       " 0.028328625613878538,\n",
       " 0.037813295226714165,\n",
       " 0.021705157678776132,\n",
       " 0.04555046693915808,\n",
       " 0.02389135095992224,\n",
       " 0.02794657286151551,\n",
       " 0.022985174262592403,\n",
       " 0.02710105601512713,\n",
       " 0.10144501462934544,\n",
       " 0.02647457431173646,\n",
       " 0.8289872301776329,\n",
       " 0.07652637969441987,\n",
       " 0.03168546502734488,\n",
       " 0.024150713680923367,\n",
       " 0.02381312724327907,\n",
       " 0.02260879195853364,\n",
       " 0.38742458887251213,\n",
       " 0.03142558522928137,\n",
       " 0.030902596988405737,\n",
       " 0.02696232314228497,\n",
       " 0.950949196701846,\n",
       " 0.026360783705336836,\n",
       " 0.8990982783589936,\n",
       " 0.02276467130124093,\n",
       " 0.029870546825697,\n",
       " 0.9010044030773504,\n",
       " 0.04167554710523277,\n",
       " 0.044593309841425725,\n",
       " 0.9770097492422379,\n",
       " 0.02895676563685205,\n",
       " 0.02645458167048608,\n",
       " 0.20764761708887786,\n",
       " 0.02992055902171792,\n",
       " 0.03257833103875833,\n",
       " 0.024117299680117724,\n",
       " 0.0517664860888224,\n",
       " 0.13794873711398542,\n",
       " 0.02381447772932264,\n",
       " 0.5290343126161265,\n",
       " 0.05346013095484766,\n",
       " 0.024066772107372444,\n",
       " 0.03015763284131498,\n",
       " 0.032436827924209516,\n",
       " 0.029759304725501024,\n",
       " 0.025824473287386608,\n",
       " 0.031074142008446638,\n",
       " 0.20347207962993932,\n",
       " 0.3990972486926439,\n",
       " 0.026571786263040863,\n",
       " 0.025864657038504185,\n",
       " 0.8730205442612733,\n",
       " 0.022414249588113326,\n",
       " 0.02557043730622496,\n",
       " 0.03431938174389397,\n",
       " 0.02593271885321337,\n",
       " 0.8167718396645329,\n",
       " 0.026691623415735964,\n",
       " 0.9843529357476644,\n",
       " 0.02729503678846167,\n",
       " 0.02289452832508404,\n",
       " 0.024999768402143505,\n",
       " 0.7931492271598527,\n",
       " 0.039809987003714783,\n",
       " 0.028609036748971757,\n",
       " 0.8611890496076118,\n",
       " 0.027609516074997804,\n",
       " 0.2661611007700877,\n",
       " 0.9705919100875892,\n",
       " 0.02730995853005725,\n",
       " 0.02303464683435606,\n",
       " 0.9750054922947656,\n",
       " 0.02232453898414716,\n",
       " 0.024475517298254115,\n",
       " 0.0397573027144072,\n",
       " 0.024192247815922302,\n",
       " 0.18921579915920966,\n",
       " 0.02525869248125144,\n",
       " 0.8040544284078641,\n",
       " 0.03520833403977678,\n",
       " 0.0224190080440979,\n",
       " 0.0932271416441733,\n",
       " 0.5423207601857106,\n",
       " 0.5505340737437711,\n",
       " 0.032823355561286696,\n",
       " 0.032243512758784176,\n",
       " 0.026751482830398743,\n",
       " 0.028370557278127033,\n",
       " 0.0942714513319666,\n",
       " 0.03369620999270278,\n",
       " 0.9728923430053408,\n",
       " 0.03491518975534408,\n",
       " 0.8189632848382198,\n",
       " 0.06825726125146751,\n",
       " 0.024698831177744955,\n",
       " 0.6366556500970282,\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = l + l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312735"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = list(y1)\n",
    "y1_prime = y1 + list(y1_prime)\n",
    "y2 = list(y2)\n",
    "y2_prime = y2 + list(y2_prime)\n",
    "y3 = list(y3)\n",
    "y3_prime = y3 + list(y3_prime)\n",
    "y4 = list(y4)\n",
    "y4_prime = y4 + list(y4_prime)\n",
    "y5 = list(y5)\n",
    "y5_prime = y5 + list(y5_prime)\n",
    "y6 = list(y6)\n",
    "y6_prime = y6 + list(y6_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(None, dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "for y in [y1, y2, y3, y4, y5, y6]:\n",
    "    print('=========================================')\n",
    "    def objective(params):\n",
    "        params = {\n",
    "            'max_depth': int(params['max_depth']),\n",
    "            'min_child_weight': int(params['min_child_weight']),\n",
    "            'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "            'subsample': '{:.3f}'.format(params['colsample_bytree']),\n",
    "            'learning_rate': '{:.3f}'.format(params['learning_rate']),\n",
    "\n",
    "        }\n",
    "\n",
    "#         clf = lgbm.LGBMClassifier(\n",
    "#             objective='binary',\n",
    "#             n_estimators=20000,\n",
    "#             n_jobs=4,\n",
    "#             **params\n",
    "#         )\n",
    "\n",
    "        clf = xgb.XGBClassifier(\n",
    "         n_estimators=1000,\n",
    "         objective= 'binary:logistic',\n",
    "         nthread=4,\n",
    "#          scale_pos_weight=1,\n",
    "         seed=27,\n",
    "         **params)\n",
    "        score = cross_val_score(clf, X_prime, np.array(y), scoring='accuracy', cv=KFold()).mean()\n",
    "        print(\"Accuracy {:.5f} params {}\".format(score, params))\n",
    "        return score\n",
    "\n",
    "    space = {\n",
    "        'max_depth': hp.uniform('max_depth', 4, 12),\n",
    "        'min_child_weight': hp.uniform('min_child_weight', 1, 10),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "        'subsample': hp.uniform('subsample', 0.3, 1.0),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.001, 0.1),\n",
    "    }\n",
    "\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "ROC AUC 0.952 params {'num_leaves': 5396, 'colsample_bytree': '0.989', 'learning_rate': '0.049'}\n",
      "ROC AUC 0.952 params {'num_leaves': 514, 'colsample_bytree': '0.733', 'learning_rate': '0.047'}\n",
      "ROC AUC 0.953 params {'num_leaves': 7040, 'colsample_bytree': '0.797', 'learning_rate': '0.042'}\n",
      "ROC AUC 0.954 params {'num_leaves': 6022, 'colsample_bytree': '0.489', 'learning_rate': '0.006'}\n",
      "ROC AUC 0.954 params {'num_leaves': 7098, 'colsample_bytree': '0.652', 'learning_rate': '0.003'}\n",
      "ROC AUC 0.952 params {'num_leaves': 7026, 'colsample_bytree': '0.595', 'learning_rate': '0.065'}\n",
      "ROC AUC 0.952 params {'num_leaves': 5770, 'colsample_bytree': '0.655', 'learning_rate': '0.098'}\n",
      "ROC AUC 0.953 params {'num_leaves': 1960, 'colsample_bytree': '0.768', 'learning_rate': '0.014'}\n",
      "ROC AUC 0.954 params {'num_leaves': 4802, 'colsample_bytree': '0.749', 'learning_rate': '0.013'}\n",
      "ROC AUC 0.952 params {'num_leaves': 4218, 'colsample_bytree': '0.851', 'learning_rate': '0.063'}\n",
      "=========================================\n",
      "ROC AUC 0.979 params {'num_leaves': 3438, 'colsample_bytree': '0.894', 'learning_rate': '0.025'}\n",
      "ROC AUC 0.981 params {'num_leaves': 4086, 'colsample_bytree': '0.589', 'learning_rate': '0.010'}\n",
      "ROC AUC 0.979 params {'num_leaves': 6616, 'colsample_bytree': '0.852', 'learning_rate': '0.070'}\n",
      "ROC AUC 0.977 params {'num_leaves': 40, 'colsample_bytree': '0.776', 'learning_rate': '0.093'}\n",
      "ROC AUC 0.980 params {'num_leaves': 3304, 'colsample_bytree': '0.455', 'learning_rate': '0.059'}\n",
      "ROC AUC 0.980 params {'num_leaves': 5096, 'colsample_bytree': '0.737', 'learning_rate': '0.047'}\n",
      "ROC AUC 0.979 params {'num_leaves': 2708, 'colsample_bytree': '0.450', 'learning_rate': '0.083'}\n",
      "ROC AUC 0.982 params {'num_leaves': 5546, 'colsample_bytree': '0.485', 'learning_rate': '0.005'}\n",
      "ROC AUC 0.979 params {'num_leaves': 3612, 'colsample_bytree': '0.906', 'learning_rate': '0.057'}\n",
      "ROC AUC 0.980 params {'num_leaves': 2028, 'colsample_bytree': '0.437', 'learning_rate': '0.028'}\n",
      "=========================================\n",
      "ROC AUC 0.969 params {'num_leaves': 3420, 'colsample_bytree': '0.583', 'learning_rate': '0.092'}\n",
      "ROC AUC 0.970 params {'num_leaves': 7248, 'colsample_bytree': '0.652', 'learning_rate': '0.042'}\n",
      "ROC AUC 0.970 params {'num_leaves': 6724, 'colsample_bytree': '0.634', 'learning_rate': '0.050'}\n",
      "ROC AUC 0.971 params {'num_leaves': 804, 'colsample_bytree': '0.836', 'learning_rate': '0.009'}\n",
      "ROC AUC 0.970 params {'num_leaves': 7896, 'colsample_bytree': '0.991', 'learning_rate': '0.022'}\n",
      "ROC AUC 0.969 params {'num_leaves': 4420, 'colsample_bytree': '0.987', 'learning_rate': '0.091'}\n",
      "ROC AUC 0.969 params {'num_leaves': 3346, 'colsample_bytree': '0.453', 'learning_rate': '0.078'}\n",
      "ROC AUC 0.969 params {'num_leaves': 132, 'colsample_bytree': '0.606', 'learning_rate': '0.092'}\n",
      "ROC AUC 0.970 params {'num_leaves': 2384, 'colsample_bytree': '0.731', 'learning_rate': '0.053'}\n",
      "ROC AUC 0.970 params {'num_leaves': 3616, 'colsample_bytree': '0.658', 'learning_rate': '0.037'}\n",
      "=========================================\n",
      "ROC AUC 0.943 params {'num_leaves': 7114, 'colsample_bytree': '0.953', 'learning_rate': '0.091'}\n",
      "ROC AUC 0.945 params {'num_leaves': 2328, 'colsample_bytree': '0.553', 'learning_rate': '0.077'}\n",
      "ROC AUC 0.949 params {'num_leaves': 5176, 'colsample_bytree': '0.989', 'learning_rate': '0.026'}\n",
      "ROC AUC 0.954 params {'num_leaves': 5112, 'colsample_bytree': '0.499', 'learning_rate': '0.012'}\n",
      "ROC AUC 0.949 params {'num_leaves': 2462, 'colsample_bytree': '0.426', 'learning_rate': '0.027'}\n",
      "ROC AUC 0.957 params {'num_leaves': 4148, 'colsample_bytree': '0.549', 'learning_rate': '0.005'}\n",
      "ROC AUC 0.950 params {'num_leaves': 5026, 'colsample_bytree': '0.443', 'learning_rate': '0.033'}\n",
      "ROC AUC 0.950 params {'num_leaves': 7526, 'colsample_bytree': '0.422', 'learning_rate': '0.032'}\n",
      "ROC AUC 0.950 params {'num_leaves': 7574, 'colsample_bytree': '0.363', 'learning_rate': '0.034'}\n",
      "ROC AUC 0.948 params {'num_leaves': 2640, 'colsample_bytree': '0.821', 'learning_rate': '0.046'}\n",
      "=========================================\n",
      "ROC AUC 0.960 params {'num_leaves': 3036, 'colsample_bytree': '0.745', 'learning_rate': '0.099'}\n",
      "ROC AUC 0.962 params {'num_leaves': 6364, 'colsample_bytree': '0.520', 'learning_rate': '0.028'}\n",
      "ROC AUC 0.962 params {'num_leaves': 6300, 'colsample_bytree': '0.757', 'learning_rate': '0.020'}\n",
      "ROC AUC 0.962 params {'num_leaves': 3404, 'colsample_bytree': '0.452', 'learning_rate': '0.024'}\n",
      "ROC AUC 0.960 params {'num_leaves': 3764, 'colsample_bytree': '0.380', 'learning_rate': '0.091'}\n",
      "ROC AUC 0.961 params {'num_leaves': 2630, 'colsample_bytree': '0.337', 'learning_rate': '0.049'}\n",
      "ROC AUC 0.961 params {'num_leaves': 2550, 'colsample_bytree': '0.779', 'learning_rate': '0.066'}\n",
      "ROC AUC 0.961 params {'num_leaves': 1988, 'colsample_bytree': '0.348', 'learning_rate': '0.043'}\n",
      "ROC AUC 0.962 params {'num_leaves': 6280, 'colsample_bytree': '0.432', 'learning_rate': '0.020'}\n",
      "ROC AUC 0.961 params {'num_leaves': 1126, 'colsample_bytree': '0.712', 'learning_rate': '0.063'}\n",
      "=========================================\n",
      "ROC AUC 0.936 params {'num_leaves': 940, 'colsample_bytree': '0.768', 'learning_rate': '0.094'}\n",
      "ROC AUC 0.949 params {'num_leaves': 7952, 'colsample_bytree': '0.535', 'learning_rate': '0.002'}\n",
      "ROC AUC 0.937 params {'num_leaves': 3908, 'colsample_bytree': '0.558', 'learning_rate': '0.074'}\n",
      "ROC AUC 0.941 params {'num_leaves': 6838, 'colsample_bytree': '0.858', 'learning_rate': '0.016'}\n",
      "ROC AUC 0.940 params {'num_leaves': 1726, 'colsample_bytree': '0.756', 'learning_rate': '0.027'}\n",
      "ROC AUC 0.944 params {'num_leaves': 1098, 'colsample_bytree': '0.374', 'learning_rate': '0.014'}\n",
      "ROC AUC 0.939 params {'num_leaves': 3702, 'colsample_bytree': '0.842', 'learning_rate': '0.047'}\n",
      "ROC AUC 0.937 params {'num_leaves': 774, 'colsample_bytree': '0.531', 'learning_rate': '0.097'}\n",
      "ROC AUC 0.939 params {'num_leaves': 6902, 'colsample_bytree': '0.487', 'learning_rate': '0.068'}\n",
      "ROC AUC 0.942 params {'num_leaves': 2278, 'colsample_bytree': '0.711', 'learning_rate': '0.018'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for y in [y1, y2, y3, y4, y5, y6]:\n",
    "    print('=========================================')\n",
    "    def objective(params):\n",
    "        params = {\n",
    "            'num_leaves': int(params['num_leaves']),\n",
    "            'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "            'learning_rate': '{:.3f}'.format(params['learning_rate']),\n",
    "\n",
    "        }\n",
    "\n",
    "        clf = lgbm.LGBMClassifier(\n",
    "            n_estimators=20000,\n",
    "            n_jobs=4,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "\n",
    "        score = cross_val_score(clf, X, y, scoring='roc_auc', cv=StratifiedKFold()).mean()\n",
    "        print(\"ROC AUC {:.5f} params {}\".format(score, params))\n",
    "        return score\n",
    "\n",
    "    space = {\n",
    "        'num_leaves': hp.quniform('num_leaves', 31, 8192, 2),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.001, 0.1),\n",
    "    }\n",
    "\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312735"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y1_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    265090\n",
       "1     47645\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(y1_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_p = [1 if i >= 0.5 else 0 for i in y1_prime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-50f070335adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1_p\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not iterable"
     ]
    }
   ],
   "source": [
    "sum(y1_p ==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "        colsample_bytree=0.749, learning_rate=0.013, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=20000, n_jobs=4, num_leaves=4802, objective='binary',\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ROC AUC 0.954 params {'num_leaves': 4802, 'colsample_bytree': '0.749', 'learning_rate': '0.013'}\n",
    "params = {\n",
    "    'num_leaves': 4802,\n",
    "    'colsample_bytree': 0.749,\n",
    "    'learning_rate': 0.013\n",
    "\n",
    "}\n",
    "\n",
    "clf = lgbm.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    n_estimators=20000,\n",
    "    n_jobs=4,\n",
    "    **params\n",
    ")\n",
    "\n",
    "clf.fit(X_prime, y1_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = clf.predict_proba(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.02664568e-11, 1.00000000e+00],\n",
       "       [9.99999900e-01, 1.00269974e-07],\n",
       "       [1.00000000e+00, 1.34661733e-10],\n",
       "       ...,\n",
       "       [1.00000000e+00, 2.16064297e-10],\n",
       "       [9.99999999e-01, 5.44942901e-10],\n",
       "       [9.61323414e-07, 9.99999039e-01]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_p = [1 if i >= 0.5 else 0 for i in y2_prime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "        colsample_bytree=0.485, learning_rate=0.005, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=20000, n_jobs=4, num_leaves=5546, objective='binary',\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ROC AUC 0.982 params {'num_leaves': 5546, 'colsample_bytree': '0.485', 'learning_rate': '0.005'}\n",
    "params = {\n",
    "    'num_leaves': 5546,\n",
    "    'colsample_bytree': 0.485,\n",
    "    'learning_rate': 0.005\n",
    "}\n",
    "\n",
    "clf = lgbm.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    n_estimators=20000,\n",
    "    n_jobs=4,\n",
    "    \n",
    "    **params\n",
    ")\n",
    "\n",
    "clf.fit(X_prime, y2_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = clf.predict_proba(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3_p = [1 if i >= 0.5 else 0 for i in y3_prime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "        colsample_bytree=0.836, learning_rate=0.009, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=20000, n_jobs=4, num_leaves=804, objective='binary',\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ROC AUC 0.971 params {'num_leaves': 804, 'colsample_bytree': '0.836', 'learning_rate': '0.009'}\n",
    "params = {\n",
    "    'num_leaves': 804,\n",
    "    'colsample_bytree': 0.836,\n",
    "    'learning_rate': 0.009\n",
    "}\n",
    "\n",
    "clf = lgbm.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    n_estimators=20000,\n",
    "    n_jobs=4,\n",
    "    \n",
    "    **params\n",
    ")\n",
    "\n",
    "clf.fit(X_prime, y3_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = clf.predict_proba(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y4_p = [1 if i >= 0.5 else 0 for i in y4_prime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "        colsample_bytree=0.549, learning_rate=0.005, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=20000, n_jobs=4, num_leaves=4148, objective='binary',\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ROC AUC 0.957 params {'num_leaves': 4148, 'colsample_bytree': '0.549', 'learning_rate': '0.005'}\n",
    "params = {\n",
    "    'num_leaves': 4148,\n",
    "    'colsample_bytree': 0.549,\n",
    "    'learning_rate': 0.005\n",
    "}\n",
    "\n",
    "clf = lgbm.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    n_estimators=20000,\n",
    "    n_jobs=4,\n",
    "    \n",
    "    **params\n",
    ")\n",
    "\n",
    "clf.fit(X_prime, y4_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = clf.predict_proba(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y5_p = [1 if i >= 0.5 else 0 for i in y5_prime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "        colsample_bytree=0.432, learning_rate=0.02, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=20000, n_jobs=4, num_leaves=6280, objective='binary',\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROC AUC 0.962 params {'num_leaves': 6280, 'colsample_bytree': '0.432', 'learning_rate': '0.020'}\n",
    "params = {\n",
    "    'num_leaves': 6280,\n",
    "    'colsample_bytree': 0.432,\n",
    "    'learning_rate': 0.020\n",
    "}\n",
    "\n",
    "clf = lgbm.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    n_estimators=20000,\n",
    "    n_jobs=4,\n",
    "    \n",
    "    **params\n",
    ")\n",
    "\n",
    "clf.fit(X_prime, y5_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = clf.predict_proba(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y6_p = [1 if i >= 0.5 else 0 for i in y6_prime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC 0.962 params {'num_leaves': 6280, 'colsample_bytree': '0.432', 'learning_rate': '0.020'}\n",
    "params = {\n",
    "    'num_leaves': 6280,\n",
    "    'colsample_bytree': 0.432,\n",
    "    'learning_rate': 0.020\n",
    "}\n",
    "\n",
    "clf = lgbm.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    n_estimators=20000,\n",
    "    n_jobs=4,\n",
    "    \n",
    "    **params\n",
    ")\n",
    "\n",
    "clf.fit(X_prime, y6_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\"objective\": \"binary\",\n",
    "#           \"boosting_type\": \"gbdt\",\n",
    "#           \"learning_rate\": learning_rate,\n",
    "#           \"num_leaves\": int(num_leaves),\n",
    "#            \"max_bin\": 256,\n",
    "#           \"feature_fraction\": feature_fraction,\n",
    "#           \"verbosity\": 0,\n",
    "#           \"drop_rate\": 0.1,\n",
    "#           \"is_unbalance\": False,\n",
    "#           \"max_drop\": 50,\n",
    "#           \"min_child_samples\": 10,\n",
    "#           \"min_child_weight\": 150,\n",
    "#           \"min_split_gain\": 0,\n",
    "#           \"subsample\": 0.9\n",
    "#           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15294"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y1 == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15294"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y1 == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10600442204925248"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y1 == 1)/sum(y1 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.433568719759382"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y1 == 0)/sum(y1==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.04451410658307"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y2 == 0)/sum(y2==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.886377086045687"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y3 == 0)/sum(y3==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332.8305439330544"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y4 == 0)/sum(y4==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.25783927891329"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y5 == 0)/sum(y5==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112.57366548042705"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y6 == 0)/sum(y6==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_wts = [9.433568719759382, 99.04451410658307, 17.886377086045687, 332.8305439330544, 19.25783927891329, \n",
    "       112.57366548042705]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "ROC AUC 0.80387 params {'num_leaves': 4044, 'colsample_bytree': '0.674', 'subsample': '0.424', 'learning_rate': '0.035'}\n",
      "ROC AUC 0.80013 params {'num_leaves': 6536, 'colsample_bytree': '0.634', 'subsample': '0.454', 'learning_rate': '0.045'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0b4cdbd05929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 max_evals=10)\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-0b4cdbd05929>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROC AUC {:.5f} params {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    677\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    471\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1519\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for y in [y1, y2, y3, y4, y5, y6]:\n",
    "    print('=========================================')\n",
    "    def objective(params):\n",
    "        params = {\n",
    "            'num_leaves': int(params['num_leaves']),\n",
    "            'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "            'subsample': '{:.3f}'.format(params['subsample']),\n",
    "            'learning_rate': '{:.3f}'.format(params['learning_rate']),\n",
    "\n",
    "        }\n",
    "        \n",
    "        scale_pos_wt = scale_pos_wts[n]\n",
    "        clf = lgbm.LGBMClassifier(\n",
    "            n_estimators=5000,\n",
    "#             is_unbalance=True,\n",
    "            scale_pos_weight = scale_pos_wt,\n",
    "            objective=\"binary\",\n",
    "            boosting_type= \"gbdt\",\n",
    "            n_jobs=4,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "\n",
    "        score = cross_val_score(clf, X, y, scoring='roc_auc', cv=StratifiedKFold(shuffle=True)).mean()\n",
    "        print(\"ROC AUC {:.5f} params {}\".format(score, params))\n",
    "        return score\n",
    "\n",
    "    space = {\n",
    "        'num_leaves': hp.quniform('num_leaves', 31, 8192, 2),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "        'subsample': hp.uniform('subsample', 0.3, 1.0),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.001, 0.1),\n",
    "    }\n",
    "\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=10)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../submissions/submission_0.986.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 83)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 83)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
    "       'identity_hate']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t1 = np.hstack([X_t, Y1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 83)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 89)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.vstack([X, X_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.vstack([y, Y1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/ktc/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/watts/anaconda3/envs/ktc/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# ROC AUC 0.90463 params {'num_leaves': 5724, 'colsample_bytree': '0.757', 'subsample': '0.887', 'learning_rate': '0.091'}\n",
    "for y in [Y]:\n",
    "    print('=========================================')\n",
    "    def objective(params):\n",
    "        params = {\n",
    "            'num_leaves': int(params['num_leaves']),\n",
    "            'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "            'subsample': '{:.3f}'.format(params['subsample']),\n",
    "            'learning_rate': '{:.3f}'.format(params['learning_rate']),\n",
    "\n",
    "        }\n",
    "        \n",
    "#         scale_pos_wt = scale_pos_wts[n]\n",
    "        clf = lgbm.LGBMClassifier(\n",
    "            n_estimators=5000,\n",
    "#             is_unbalance=True,\n",
    "#             scale_pos_weight = scale_pos_wt,\n",
    "            objective=\"multiclass\",\n",
    "            boosting_type= \"gbdt\",\n",
    "            n_jobs=4,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "\n",
    "        score = cross_val_score(clf, X, y, scoring='accuracy', cv=StratifiedKFold(shuffle=True)).mean()\n",
    "        print(\"Accuracy {:.5f} params {}\".format(score, params))\n",
    "        return score\n",
    "\n",
    "    space = {\n",
    "        'num_leaves': hp.quniform('num_leaves', 31, 8192, 2),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "        'subsample': hp.uniform('subsample', 0.3, 1.0),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.001, 0.1),\n",
    "    }\n",
    "\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=10)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12    0.5           0.5      0.5     0.5     0.5   \n",
       "1  0000247867823ef7    0.5           0.5      0.5     0.5     0.5   \n",
       "2  00013b17ad220c46    0.5           0.5      0.5     0.5     0.5   \n",
       "3  00017563c3f7919a    0.5           0.5      0.5     0.5     0.5   \n",
       "4  00017695ad8997eb    0.5           0.5      0.5     0.5     0.5   \n",
       "\n",
       "   identity_hate  \n",
       "0            0.5  \n",
       "1            0.5  \n",
       "2            0.5  \n",
       "3            0.5  \n",
       "4            0.5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toxic, severe_toxic, obscene, threat, insult, identity_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC AUC 0.954 params {'num_leaves': 7098, 'colsample_bytree': '0.652', 'learning_rate': '0.003'}\n",
    "params = {\n",
    "            'num_leaves': 7098,\n",
    "            'colsample_bytree': 0.652,\n",
    "            'learning_rate': 0.003\n",
    "        }\n",
    "\n",
    "clf = lgbm.LGBMClassifier(\n",
    "    n_estimators=20000,\n",
    "    n_jobs=4,\n",
    "    objective='roc_auc',\n",
    "    **params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "LightGBMError",
     "evalue": "b'No object function provided'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-afd4cda53619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    677\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    471\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1519\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \"\"\"\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: b'No object function provided'"
     ]
    }
   ],
   "source": [
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "No booster found. Need to call fit beforehand.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2345cf2b3d2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_y1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, num_iteration)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0mclass_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         \u001b[0mclass_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, raw_score, num_iteration)\u001b[0m\n\u001b[1;32m    717\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                              % (self._n_features, n_features))\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0mclass_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_classes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mclass_probs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ktc/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mbooster_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;34m\"\"\"Get the underlying lightgbm Booster of this model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLGBMNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No booster found. Need to call fit beforehand.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: No booster found. Need to call fit beforehand."
     ]
    }
   ],
   "source": [
    "pred_y1 = clf.predict(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_y1 = clf.predict_proba(X_t)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['toxic'] = proba_y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = RandomForestClassifier(\n",
    "#             n_estimators=500,\n",
    "#             max_depth = 18,\n",
    "#             min_samples_split=16,\n",
    "#             bootstrap=False,\n",
    "#             max_features=0.1,\n",
    "#             n_jobs=8,\n",
    "#             random_state=seed,\n",
    "#             verbose=True,\n",
    "#             )\n",
    "\n",
    "# make_mf_classification(X ,y, clf, X_t, n_folds=5,seed=seed,nb_epoch=1,max_features=1.0,name='rf_3',path=path)\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# clf = ExtraTreesClassifier(\n",
    "#             n_estimators=500,\n",
    "#             max_depth = 23,\n",
    "#             min_samples_split=8,\n",
    "#             bootstrap=False,\n",
    "#             max_features=0.3,\n",
    "#             n_jobs=8,\n",
    "#             random_state=seed,\n",
    "#             verbose=True,\n",
    "#             )\n",
    "\n",
    "# make_mf_classification(X ,y, clf, X_t, n_folds=5,seed=seed,nb_epoch=1,max_features=1.0,name='et_3',path=path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = xgb.XGBClassifier(\n",
    "#         n_estimators=9326/3,\n",
    "#         learning_rate = 0.093/3,\n",
    "#         max_depth=8,\n",
    "#         subsample=0.75,\n",
    "#         colsample_bytree = 0.54,\n",
    "#         gamma = 0.3,\n",
    "#         reg_lambda=0,\n",
    "#         min_child_weight=13,\n",
    "#         seed = seed,\n",
    "#         )\n",
    "# make_mf_classification(X ,y, clf, X_t, n_folds=5,seed=seed,nb_epoch=1,max_features=1.0,name='xgb_3',path=path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint,Callback\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Embedding, LSTM, Dense,Flatten, Dropout, merge,Convolution1D,MaxPooling1D,Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD,Nadam\n",
    "from keras.layers.advanced_activations import PReLU,LeakyReLU,ELU\n",
    "from keras.models import Model\n",
    "from keras.utils.visualize_util import plot\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "def build_model(maxlen=238,hidden=512):\n",
    "    inputs = []\n",
    "    inputs_q1 = Input(shape=(maxlen,),name='input_q1',sparse=False)\n",
    "    inputs.append(inputs_q1)\n",
    "\n",
    "    fc1 = Dense(hidden)(inputs_q1)\n",
    "    fc1 = PReLU()(fc1)\n",
    "    fc1 = BatchNormalization()(fc1)\n",
    "    fc1 = Dropout(0.2)(fc1)\n",
    "\n",
    "    fc1 = Dense(hidden)(fc1)\n",
    "    fc1 = PReLU()(fc1)\n",
    "    fc1 = BatchNormalization()(fc1)\n",
    "    fc1 = Dropout(0.2)(fc1)\n",
    "\n",
    "    fc1 = Dense(hidden)(fc1)\n",
    "    fc1 = PReLU()(fc1)\n",
    "    fc1 = BatchNormalization()(fc1)\n",
    "    fc1 = Dropout(0.2)(fc1)\n",
    "\n",
    "    \n",
    "    outputs = Dense(1,activation='sigmoid')(fc1)\n",
    "    model = Model(input=inputs, output=outputs)\n",
    "\n",
    "    model.compile(\n",
    "                optimizer='adam',\n",
    "                loss = 'binary_crossentropy',\n",
    "              )\n",
    "    return model\n",
    "\n",
    "class NN(BaseEstimator):\n",
    "    def __init__(self,input_shape,hidden=128):\n",
    "        self.input_shape = input_shape\n",
    "        self.hidden = hidden\n",
    "    def fit(self,X,y):\n",
    "        model = build_model(maxlen=self.input_shape,hidden=self.hidden)\n",
    "        model.fit(X,y,epochs=250,batch_size=128,shuffle=True,verbose=1)\n",
    "        self.model=model\n",
    "    def predict_proba(self,X):\n",
    "        y_p = self.model.predict(X,batch_size=1024).ravel()\n",
    "        y_p_inv= np.ones(y_p.shape[0])-y_p\n",
    "        y_p = np.hstack([y_p_inv.reshape(-1,1),y_p.reshape(-1,1)])\n",
    "        return y_p\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "clf = NN(X.shape[1],128)\n",
    "make_mf_classification(scaler.transform(X) ,y, clf, scaler.transform(X_t), n_folds=5,seed=seed,nb_epoch=1,max_features=1.0,name='nn_3',path=path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ktc",
   "language": "python",
   "name": "ktc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
