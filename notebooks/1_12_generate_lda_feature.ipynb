{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watts/anaconda3/envs/ktc/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n",
      "iteration: 2 of max_iter: 10\n",
      "iteration: 3 of max_iter: 10\n",
      "iteration: 4 of max_iter: 10\n",
      "iteration: 5 of max_iter: 10\n",
      "iteration: 6 of max_iter: 10\n",
      "iteration: 7 of max_iter: 10\n",
      "iteration: 8 of max_iter: 10\n",
      "iteration: 9 of max_iter: 10\n",
      "iteration: 10 of max_iter: 10\n",
      "(159571, 10)\n",
      "(153164, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# from config import path\n",
    "\n",
    "path = '../cache/'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    seed = 1024\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    ft = ['comment_text']\n",
    "    train = pd.read_csv(\"../data/train.csv\")[ft]\n",
    "    test = pd.read_csv(\"../data/test.csv\")[ft]\n",
    "\n",
    "    print(test.shape)\n",
    "    len_train = train.shape[0]\n",
    "    lda = LatentDirichletAllocation(n_topics=10, doc_topic_prior=None, topic_word_prior=None, learning_method='batch', learning_decay=0.7, learning_offset=10.0, max_iter=10, batch_size=128, evaluate_every=-1, total_samples=1000000.0, perp_tol=0.1, mean_change_tol=0.001, max_doc_update_iter=100, n_jobs=8, verbose=1, random_state=seed)\n",
    "    bow = CountVectorizer(ngram_range=(1,1),max_df=0.95,min_df=3,stop_words='english')\n",
    "    vect_orig = make_pipeline(bow,lda)\n",
    "\n",
    "    corpus = []\n",
    "    for f in ft:\n",
    "        train[f] = train[f].astype(str)\n",
    "        test[f] = test[f].astype(str)\n",
    "        corpus+=train[f].values.tolist()\n",
    "\n",
    "    vect_orig.fit(\n",
    "        corpus\n",
    "        )\n",
    "\n",
    "    for f in ft:\n",
    "        train_lda = vect_orig.transform(train[f].values.tolist())\n",
    "        test_lda = vect_orig.transform(test[f].values.tolist())\n",
    "        print(train_lda.shape)\n",
    "        print(test_lda.shape)\n",
    "        pd.to_pickle(train_lda,path+'train_%s_lda.pkl'%f)\n",
    "        pd.to_pickle(test_lda,path+'test_%s_lda.pkl'%f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ktc",
   "language": "python",
   "name": "ktc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
